#-----------------------------------------------------------------------------#
# Download datasets
import pandas as pd
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1 import ImageGrid
import shutil
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, add, BatchNormalization, Activation, LeakyReLU, Layer
from tensorflow.keras.models import Model
from tensorflow.keras.applications import VGG19
from tensorflow.keras.utils import image_dataset_from_directory
from PIL import Image

# Directory containing the dataset
dir_dataset = "E:/deep learning/3-/2- SRGAN/srgan-dataset/Clean_Data_Resized-1024x1024"

# List all image files in the dataset directory
files_img = [os.path.join(dir_dataset, x) for x in os.listdir(dir_dataset)]

#-----------------------------------------------------------------------------#
def plot_images(images, titles, figsize, rows=1, cols=1, axes_pad=(0.1, 0.5)):
    """
    Plot multiple images in a grid.

    Parameters:
    - images (list): List of images to plot.
    - titles (list): List of titles for each image.
    - figsize (tuple): Figure size.
    - rows (int): Number of rows in the grid.
    - cols (int): Number of columns in the grid.
    - axes_pad (tuple): Padding between axes.

    Returns:
    - None
    """
    # Create a new figure with the specified size
    fig = plt.figure(figsize=figsize)
    
    # Create an image grid within the figure. 
    grid = ImageGrid(fig, 111, nrows_ncols=(rows, cols), axes_pad=axes_pad)

    # Iterate over the grid axes, the list of images, and the list of titles simultaneously
    for ax, img, title in zip(grid, images, titles):
        # Convert the image from BGR (OpenCV format) to RGB (Matplotlib format) and display it
        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        
        # Set the title for the current subplot
        ax.set_title(title)
        
        # Turn off minor ticks on the axes
        ax.minorticks_off()
        
        # Remove x-axis tick labels
        ax.set_xticklabels([])
        
        # Remove y-axis tick labels
        ax.set_yticklabels([])

    # Display the figure with the plotted images
    plt.show()

#-----------------------------------------------------------------------------#
def downsample(img_file, scale=0.3):
    """
    Downsample an image by a given scale.

    Parameters:
    - img_file (str): Path to the image file.
    - scale (float): Scale factor to downsample the image.

    Returns:
    - img (numpy.ndarray): Original image.
    - img_small (numpy.ndarray): Downsampled image.
    """
    # Read the image from the specified file path
    img = cv2.imread(img_file, cv2.IMREAD_UNCHANGED)
    
    # Resize the image by the specified scale using nearest neighbor interpolation
    img_small = cv2.resize(img, (0, 0), fx=scale, fy=scale, interpolation=cv2.INTER_NEAREST)
    
    # Return the original and downsampled images
    return img, img_small

# Downsample an example image for plotting
# Downsample the image at index 201 in the files_img list with a scale of 0.25
_, img_small = downsample(files_img[201], scale=0.25)

# Resize the downsampled image for comparison
# Read the original image from the file
img = cv2.imread(files_img[201], cv2.IMREAD_UNCHANGED)

# Resize the downsampled image to the size of the original image
img_small_resize = cv2.resize(img_small, (img.shape[1], img.shape[0]))

# Plot original and downsampled images
titles = ["original", "downsampled"]
images = [img, img_small_resize]

# Call the plot_images function to display the images
plot_images(images, titles, figsize=(10., 4.), cols=len(images))

#-----------------------------------------------------------------------------#

# Directory to save downsampled images
dir_dataset_lr = 'E:/deep learning/3-/2- SRGAN/srgan-dataset/Clean_Data_Resized_lr'

# Create directory if it doesn't exist
if not os.path.exists(dir_dataset_lr):
    os.makedirs(dir_dataset_lr)

# Downsample and save all images in the dataset
for file_img in files_img:
    # Downsample each image in the files_img list
    img, img_small = downsample(file_img, scale=0.25)
    
    # Construct the path to save the downsampled image
    file_img_lr = os.path.join(dir_dataset_lr, os.path.basename(file_img))
    
    # Save the downsampled image to the specified path
    cv2.imwrite(file_img_lr, img_small)

# List all downsampled image files
files_img_lr = [os.path.join(dir_dataset_lr, x) for x in os.listdir(dir_dataset_lr)]

# Print the count of high-resolution (HR) and low-resolution (LR) images
print("HR images: {}, LR images: {}".format(len(files_img), len(files_img_lr)))


#-----------------------------------------------------------------------------#
def generator_model(input_shape):
    """
    Build the generator model.

    Parameters:
    - input_shape (tuple): Shape of the input image.

    Returns:
    - model (tf.keras.Model): Generator model.
    """
    # Initialize variables
    g_init = tf.random_normal_initializer(1., 0.02)  # Initialize the gamma parameter for Batch Normalization layers
    relu = Activation('relu')  # Define ReLU activation function

    # Define input layer
    layer_input = Input(shape=input_shape)

    # First convolutional layer
    layer_past_block = Conv2D(64, (3, 3), padding='SAME', activation='relu', kernel_initializer='HeNormal')(layer_input)
    layer_initial = layer_past_block  # Store this layer for later use in residual connections

    # Residual blocks
    for i in range(16):
        layer = Conv2D(64, (3, 3), padding='SAME', kernel_initializer='HeNormal')(layer_past_block)
        layer = BatchNormalization(gamma_initializer=g_init)(layer)
        layer = add([layer_past_block, layer])  # Add skip connection
        layer_past_block = layer

    # Final residual connection
    layer = Conv2D(64, (3, 3), padding='SAME', kernel_initializer='HeNormal')(layer_past_block)
    layer = BatchNormalization(gamma_initializer=g_init)(layer)
    layer = add([layer, layer_initial])  # Add skip connection with the initial layer

    # Upsampling layers
    layer = Conv2D(256, (3, 3), padding='SAME', kernel_initializer='HeNormal')(layer)
    layer = SubpixelConv2D(upsampling_factor=2)(layer)  # Custom sub-pixel convolution layer for upsampling
    layer = relu(layer)

    layer = Conv2D(256, (3, 3), padding='SAME', kernel_initializer='HeNormal')(layer)
    layer = SubpixelConv2D(upsampling_factor=2)(layer)
    layer = relu(layer)

    # Final output layer
    layer_final = Conv2D(3, (1, 1), padding='SAME', kernel_initializer='HeNormal', activation='relu')(layer)

    # Define the model
    model = Model(inputs=layer_input, outputs=layer_final, name="generator")
    return model

class SubpixelConv2D(Layer):
    def __init__(self, upsampling_factor=2, **kwargs):
        """
        Custom layer for sub-pixel convolution.

        Parameters:
        - upsampling_factor (int): Factor by which to upsample.
        """
        super(SubpixelConv2D, self).__init__(**kwargs)
        self.upsampling_factor = upsampling_factor

    def build(self, input_shape):
        last_dim = input_shape[-1]
        factor = self.upsampling_factor * self.upsampling_factor
        if last_dim % factor != 0:
            raise ValueError('Channel ' + str(last_dim) + ' should be an integer multiple of upsampling_factor^2: ' + str(factor) + '.')

    def call(self, inputs, **kwargs):
        return tf.nn.depth_to_space(inputs, self.upsampling_factor)

    def get_config(self):
        config = {'upsampling_factor': self.upsampling_factor}
        base_config = super(SubpixelConv2D, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))

    def compute_output_shape(self, input_shape):
        factor = self.upsampling_factor * self.upsampling_factor
        input_shape_1 = input_shape[1] * self.upsampling_factor if input_shape[1] is not None else None
        input_shape_2 = input_shape[2] * self.upsampling_factor if input_shape[2] is not None else None
        dims = [input_shape[0], input_shape_1, input_shape_2, int(input_shape[3] / factor)]
        return tuple(dims)

#-----------------------------------------------------------------------------#

def discriminator_model(input_shape):
    """
    Build the discriminator model.

    Parameters:
    - input_shape (tuple): Shape of the input image.

    Returns:
    - model (tf.keras.Model): Discriminator model.
    """
    # Initialize variables
    g_init = tf.random_normal_initializer(1., 0.02)  # Initialize the gamma parameter for Batch Normalization layers
    ly_relu = LeakyReLU(alpha=0.2)  # Define Leaky ReLU activation function
    df_dim = 16  # Dimension factor for the discriminator

    # Define input layer
    layer_input = Input(input_shape)

    # First convolutional layer
    layer = Conv2D(64, (4, 4), (2, 2), padding='SAME', kernel_initializer='HeNormal')(layer_input)
    layer = ly_relu(layer)

    # Convolutional layers with increasing filters
    for i in range(2, 6):
        layer = Conv2D(df_dim * (2 ** i), (4, 4), (2, 2), padding='SAME', kernel_initializer='HeNormal')(layer)
        layer = ly_relu(layer)
        layer = BatchNormalization(gamma_initializer=g_init)(layer)

    # Additional convolutional layers
    layer = Conv2D(df_dim * 16, (1, 1), (1, 1), padding='SAME', kernel_initializer='HeNormal')(layer)
    layer = ly_relu(layer)
    layer = BatchNormalization(gamma_initializer=g_init)(layer)

    layer = Conv2D(df_dim * 8, (1, 1), (1, 1), padding='SAME', kernel_initializer='HeNormal')(layer)
    layer = BatchNormalization(gamma_initializer=g_init)(layer)
    layer_past = layer  # Store this layer for the residual block

    # Residual Block
    layer = Conv2D(df_dim * 4, (3, 3), (1, 1), padding='SAME', kernel_initializer='HeNormal')(layer)
    layer = ly_relu(layer)
    layer = Conv2D(df_dim * 8, (3, 3), (1, 1), padding='SAME', kernel_initializer='HeNormal')(layer)
    layer = BatchNormalization(gamma_initializer=g_init)(layer)
    layer = add([layer_past, layer])  # Add skip connection
    layer = ly_relu(layer)

    # Flatten the output and add dense layers
    layer = Flatten()(layer)
    layer = Dense(1024)(layer)
    layer = ly_relu(layer)
    layer_final = Dense(1, activation='sigmoid')(layer)  # Final output layer with sigmoid activation

    # Define the model
    model = Model(inputs=layer_input, outputs=layer_final, name="discriminator")
    return model

#-----------------------------------------------------------------------------#
def adversarial_loss(y_true, y_pred):
    """
    Compute adversarial loss.

    Parameters:
    - y_true (tensor): Ground truth labels.
    - y_pred (tensor): Predicted labels.

    Returns:
    - loss (tensor): Adversarial loss.
    """
    return tf.keras.losses.binary_crossentropy(y_true, y_pred)

def content_loss(y_true, y_pred):
    """
    Compute content loss using VGG19.

    Parameters:
    - y_true (tensor): Ground truth images.
    - y_pred (tensor): Generated images.

    Returns:
    - loss (tensor): Content loss.
    """
    y_true = tf.keras.applications.vgg19.preprocess_input(y_true)
    y_pred = tf.keras.applications.vgg19.preprocess_input(y_pred)

    vgg19 = VGG19(include_top=False, input_shape=(96, 96, 3))
    loss_model = Model(vgg19.input, vgg19.get_layer("block5_conv4").output)
    loss_model.trainable = False
    return tf.keras.losses.mean_squared_error(loss_model(y_true), loss_model(y_pred))

def srgan_loss(y_true, y_pred):
    """
    Compute SRGAN loss, a combination of adversarial and content losses.

    Parameters:
    - y_true (tensor): Ground truth images.
    - y_pred (tensor): Generated images.

    Returns:
    - loss (tensor): SRGAN loss.
    """
    return content_loss(y_true, y_pred) + 1e-3 * adversarial_loss(y_true, y_pred)


#-----------------------------------------------------------------------------#
# Define image size and batch size
size_image = (96, 96)
batch_size = 8

# Load high-resolution (HR) dataset
train_hr_dataset = image_dataset_from_directory(
    dir_dataset,
    label_mode=None,
    image_size=size_image,
    batch_size=batch_size,
    interpolation='bilinear'
)

# Load low-resolution (LR) dataset
train_lr_dataset = image_dataset_from_directory(
    dir_dataset_lr,
    label_mode=None,
    image_size=size_image,
    batch_size=batch_size,
    interpolation='bilinear'
)

print(train_hr_dataset)
print(train_lr_dataset)


#-----------------------------------------------------------------------------#
# Input shape for generator and discriminator models
input_shape_gen = (96, 96, 3)
input_shape_dis = (96, 96, 3)

# Instantiate generator and discriminator models
generator = generator_model(input_shape_gen)
discriminator = discriminator_model(input_shape_dis)

# Compile generator and discriminator models
generator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999), loss=srgan_loss)
discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999), loss=adversarial_loss)


#-----------------------------------------------------------------------------#
def train_step(lr_images, hr_images):
    """
    Perform a single training step.

    Parameters:
    - lr_images (tensor): Low-resolution images.
    - hr_images (tensor): High-resolution images.

    Returns:
    - gen_loss (tensor): Generator loss.
    - disc_loss (tensor): Discriminator loss.
    """
    # Open a gradient tape to record operations for automatic differentiation
    with tf.GradientTape() as tape:
        # Generate super-resolution images from low-resolution input images
        sr_images = generator(lr_images, training=True)
        
        # Pass high-resolution images through the discriminator
        real_output = discriminator(hr_images, training=True)
        
        # Pass generated super-resolution images through the discriminator
        fake_output = discriminator(sr_images, training=True)
        
        # Compute the generator loss using content loss and adversarial loss
        gen_loss = srgan_loss(hr_images, sr_images)
        
        # Compute the discriminator loss by comparing real and fake outputs
        disc_loss = adversarial_loss(tf.ones_like(real_output), real_output) + \
                    adversarial_loss(tf.zeros_like(fake_output), fake_output)

    # Compute gradients of generator and discriminator with respect to their trainable variables
    gradients_of_generator = tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = tape.gradient(disc_loss, discriminator.trainable_variables)

    # Apply gradients to update generator and discriminator weights
    generator.optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator.optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

    return gen_loss, disc_loss


-------------------------------------------------------------------------------
def train(dataset, epochs):
    """
    Train the SRGAN model.

    Parameters:
    - dataset (tf.data.Dataset): Training dataset.
    - epochs (int): Number of epochs to train.

    Returns:
    - None
    """
    # Loop through each epoch
    for epoch in range(epochs):
        # Iterate over each batch in the dataset
        for lr_images, hr_images in dataset:
            # Perform a single training step
            gen_loss, disc_loss = train_step(lr_images, hr_images)

        # Print generator and discriminator losses at the end of each epoch
        print("Epoch: {}, Generator Loss: {}, Discriminator Loss: {}".format(epoch, gen_loss, disc_loss))

# Combine HR and LR datasets into a single dataset
dataset = tf.data.Dataset.zip((train_lr_dataset, train_hr_dataset))

# Train the model for 100 epochs
train(dataset, epochs=100)
